{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 参数管理\n",
    "\n",
    "我们首先关注具有单隐藏层的多层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(24901:281473633001696,MainProcess):2025-12-12-23:56:00.958.000 [mindspore/run_check/_check_version.py:409] Can not find the tbe operator implementation(need by mindspore-ascend). Please check whether the Environment Variable PYTHONPATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.11/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.11/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.11/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.11/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "[WARNING] CORE(24901,ffffafe8a0e0,python):2025-12-12-23:56:13.154.230 [mindspore/core/utils/ms_context.cc:537] GetJitLevel] Set jit level to O2 for rank table startup method.\n",
      "[WARNING] DEVICE(24901,ffffafe8a0e0,python):2025-12-12-23:56:13.414.633 [mindspore/ccsrc/plugin/res_manager/ascend/mem_manager/ascend_memory_adapter.cc:123] Initialize] Free memory size is less than half of total memory size.Device 0 Device MOC total size:31675383808 Device MOC free size:1757679616 may be other processes occupying this card, check as: ps -ef|grep python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2, 1], dtype=Float32, value=\n",
       "[[-5.87999701e-01],\n",
       " [-6.28293872e-01]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from d2l import mindspore as d2l\n",
    "from mindspore import nn\n",
    "\n",
    "net = nn.SequentialCell([nn.Dense(4, 8), nn.ReLU(), nn.Dense(8, 1)])\n",
    "X = d2l.rand((2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "参数访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('2.weight', Parameter (name=2.weight, shape=(1, 8), dtype=Float32, requires_grad=True)), ('2.bias', Parameter (name=2.bias, shape=(1,), dtype=Float32, requires_grad=True))])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].parameters_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'abc.Parameter'>\n",
      "Parameter (name=2.bias, shape=(1,), dtype=Float32, requires_grad=True)\n",
      "[-0.26707265]\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "一次性访问所有参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', (8, 4)) ('0.bias', (8,))\n",
      "('0.weight', (8, 4)) ('0.bias', (8,)) ('2.weight', (1, 8)) ('2.bias', (1,))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net[0].parameters_dict().items()])\n",
    "print(*[(name, param.shape) for name, param in net.parameters_dict().items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1], dtype=Float32, value= [-2.67072648e-01])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters_dict()['2.bias'].value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "从嵌套块收集参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2, 1], dtype=Float32, value=\n",
       "[[-2.32916176e-01],\n",
       " [-2.32916176e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.SequentialCell([nn.Dense(4, 8), nn.ReLU(),\n",
    "                              nn.Dense(8, 4), nn.ReLU()])\n",
    "\n",
    "def block2():\n",
    "    net = nn.SequentialCell()\n",
    "    for i in range(4):\n",
    "        # 在这里嵌套\n",
    "        net.append(block1())\n",
    "    return net\n",
    "\n",
    "rgnet = nn.SequentialCell([block2(), nn.Dense(4, 1)])\n",
    "rgnet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "我们已经设计了网络，让我们看看它是如何组织的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequentialCell(\n",
      "  (0): SequentialCell(\n",
      "    (0): SequentialCell(\n",
      "      (0): Dense(input_channels=4, output_channels=8, has_bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dense(input_channels=8, output_channels=4, has_bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): SequentialCell(\n",
      "      (0): Dense(input_channels=4, output_channels=8, has_bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dense(input_channels=8, output_channels=4, has_bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): SequentialCell(\n",
      "      (0): Dense(input_channels=4, output_channels=8, has_bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dense(input_channels=8, output_channels=4, has_bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): SequentialCell(\n",
      "      (0): Dense(input_channels=4, output_channels=8, has_bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dense(input_channels=8, output_channels=4, has_bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Dense(input_channels=4, output_channels=1, has_bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "origin_pos": 33,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[8], dtype=Float32, value= [ 2.89527867e-02,  2.29328331e-02,  3.55436355e-01,  1.04846396e-01, -2.03583434e-01,  3.80997390e-01,  2.77427226e-01, -5.64563945e-02])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].bias.value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认情况下，MindSpore会使用Normal初始化权重矩阵，\n",
    "偏置参数设置为0。\n",
    "MindSpore的`common.initializer`模块中提供了各种初始化方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "内置初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "origin_pos": 41,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[4], dtype=Float32, value= [ 4.69799712e-03, -9.98545904e-03,  6.16287021e-03, -1.65258572e-02]),\n",
       " Tensor(shape=[], dtype=Float32, value= 0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.SequentialCell([nn.Dense(4, 8, weight_init='normal', bias_init='zero'),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dense(8, 1, weight_init='normal', bias_init='zero')])\n",
    "\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "origin_pos": 45,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[4], dtype=Float32, value= [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00]),\n",
       " Tensor(shape=[], dtype=Float32, value= 0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.SequentialCell([nn.Dense(4, 8, weight_init='one', bias_init='zero'),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dense(8, 1, weight_init='one', bias_init='zero')])\n",
    "\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "对某些块应用不同的初始化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7070257  -0.520665    0.31937808 -0.35800388]\n",
      "[42. 42. 42. 42. 42. 42. 42. 42.]\n"
     ]
    }
   ],
   "source": [
    "net = nn.SequentialCell([nn.Dense(4, 8, weight_init='xavier_uniform'),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dense(8, 1, weight_init=42)])\n",
    "\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "自定义初始化\n",
    "同样，我们实现了一个`my_init`函数来应用到`net`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "origin_pos": 56,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2, 4], dtype=Float32, value=\n",
       "[[-6.20842695e+00,  9.27657318e+00, -0.00000000e+00, -9.22449112e+00],\n",
       " [ 0.00000000e+00,  0.00000000e+00,  5.89274883e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(shape):\n",
    "    weight = d2l.uniform(shape, -10, 10)\n",
    "    weight *= d2l.abs(weight) >= 5\n",
    "    return weight\n",
    "\n",
    "\n",
    "net = nn.SequentialCell([nn.Dense(4, 8, weight_init=my_init((8, 4))),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dense(8, 1, weight_init=my_init((1, 8)))])\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "origin_pos": 60,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[4], dtype=Float32, value= [ 4.20000000e+01,  1.02765732e+01,  1.00000000e+00, -8.22449112e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "参数绑定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "origin_pos": 65,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# 我们需要给共享层一个名称，以便可以引用它的参数\n",
    "shared = nn.Dense(8, 8)\n",
    "net = nn.SequentialCell([nn.Dense(4, 8),\n",
    "                         nn.ReLU(),\n",
    "                         shared,\n",
    "                         nn.ReLU(),\n",
    "                         shared,\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dense(8, 1)])\n",
    "net(X)\n",
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
